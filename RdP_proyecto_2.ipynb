{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, multilabel_confusion_matrix, f1_score, recall_score, precision_score\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from ucimlrepo import fetch_ucirepo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explicación del Proceso de Preparación y División del Conjunto de Datos del Cáncer de Mama de Wisconsin\n",
    "\n",
    "### Objetivo\n",
    "El proceso descrito se centra en la preparación y división del conjunto de datos del cáncer de mama de Wisconsin para su análisis y modelado.\n",
    "\n",
    "### Descripción del Proceso\n",
    "\n",
    "1. **Carga del Conjunto de Datos**: \n",
    "   - Se accede y carga el conjunto de datos del cáncer de mama de Wisconsin desde un repositorio en línea, específicamente de UCI (Universidad de California, Irvine).\n",
    "\n",
    "2. **Extracción de Características y Etiquetas**: \n",
    "   - Las características (`X`) y las etiquetas objetivo (`y`) se extraen del conjunto de datos. Las características incluyen diversos indicadores médicos, mientras que las etiquetas representan la presencia o ausencia de cáncer.\n",
    "\n",
    "3. **Transformación de Etiquetas**: \n",
    "   - Las etiquetas, que originalmente indican la presencia de cáncer con el número 4, se transforman a 1, y todas las demás etiquetas (indicando ausencia de cáncer) se transforman a 0. Esto simplifica el análisis convirtiéndolo en un problema de clasificación binaria.\n",
    "\n",
    "4. **Creación y Limpieza de un DataFrame de pandas**: \n",
    "   - Se crea un DataFrame usando las características y las etiquetas transformadas.\n",
    "   - Se eliminan las filas que contienen valores faltantes (NaN) para mantener la integridad y la calidad de los datos.\n",
    "\n",
    "5. **Preparación de Datos para el Modelado**: \n",
    "   - Las características y etiquetas se separan nuevamente, quedando listas para ser usadas en la formación y evaluación de modelos de aprendizaje automático.\n",
    "\n",
    "6. **División en Conjuntos de Entrenamiento y Prueba**: \n",
    "   - Los datos se dividen en conjuntos de entrenamiento y prueba. Una proporción común es reservar el 20% de los datos para pruebas, lo que permite evaluar la eficacia del modelo en datos no vistos.\n",
    "\n",
    "### Conclusión\n",
    "Este proceso meticuloso garantiza que el conjunto de datos del cáncer de mama esté bien preparado y libre de inconsistencias, lo que es fundamental para desarrollar modelos precisos y confiables en el campo de la detección y diagnóstico del cáncer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "breast_cancer_wisconsin_original = fetch_ucirepo(id=15) \n",
    "X = breast_cancer_wisconsin_original.data.features \n",
    "y = breast_cancer_wisconsin_original.data.targets\n",
    "y = np.where(y == 4, 1, 0)\n",
    "y = y.astype(int)\n",
    "y = y.flatten()\n",
    "\n",
    "data_breast_cancer = pd.DataFrame(X, columns=breast_cancer_wisconsin_original.data.feature_names)\n",
    "data_breast_cancer['label'] = y\n",
    "\n",
    "nan_rows = np.isnan(data_breast_cancer).any(axis=1)\n",
    "data_breast_cancer = data_breast_cancer[~nan_rows]\n",
    "X_breast_cancer = data_breast_cancer.drop(columns=['label']).values\n",
    "y_breast_cancer = data_breast_cancer['label'].values\n",
    "\n",
    "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "X_train_breast_cancer, X_test_breast_cancer, y_train_breast_cancer, y_test_breast_cancer = train_test_split(X_breast_cancer, y_breast_cancer, test_size=0.2, random_state=42, stratify=y_breast_cancer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explicación del Proceso de Preparación y División de Datos del Conjunto de Datos de Frijoles Secos\n",
    "\n",
    "### Objetivo\n",
    "El proceso descrito se enfoca en la preparación y división del conjunto de datos de frijoles secos para su posterior análisis y modelado.\n",
    "\n",
    "### Pasos del Proceso\n",
    "\n",
    "1. **Carga del Conjunto de Datos**: \n",
    "   - Se obtiene el conjunto de datos de frijoles secos desde un repositorio en línea, específicamente el repositorio UCI.\n",
    "\n",
    "2. **Extracción de Características y Etiquetas**: \n",
    "   - Las características (`X`) y etiquetas objetivo (`y`) se extraen del conjunto de datos cargado.\n",
    "\n",
    "3. **Transformación de Etiquetas de Texto a Numéricas**: \n",
    "   - Las etiquetas de clase, originalmente en formato de texto (como 'SEKER', 'BARBUNYA', etc.), se convierten en valores numéricos para facilitar su manejo en análisis posteriores. Cada tipo de frijol recibe un número entero único.\n",
    "\n",
    "4. **Conversión de Tipo de Dato de Etiquetas**: \n",
    "   - Las etiquetas convertidas se transforman explícitamente a tipo de dato entero para asegurar la coherencia y compatibilidad con algoritmos de aprendizaje automático.\n",
    "\n",
    "5. **Creación de un DataFrame de pandas**: \n",
    "   - Se crea un DataFrame utilizando las características y las etiquetas numéricas. Este DataFrame facilita la manipulación y análisis de los datos.\n",
    "\n",
    "6. **Limpieza de Datos**: \n",
    "   - Se eliminan las filas con valores faltantes (NaN) para asegurar la integridad de los datos.\n",
    "\n",
    "7. **Separación en Características y Etiquetas**: \n",
    "   - Las características y etiquetas se separan nuevamente en preparación para el entrenamiento del modelo.\n",
    "\n",
    "8. **División en Conjuntos de Entrenamiento y Prueba**: \n",
    "   - Finalmente, los datos se dividen en conjuntos de entrenamiento y prueba utilizando una proporción estándar (usualmente el 20% de los datos se reserva para pruebas).\n",
    "\n",
    "### Conclusión\n",
    "Este proceso resulta en un conjunto de datos limpio y bien estructurado, listo para ser utilizado en tareas de clasificación o análisis de datos. La transformación y limpieza de datos son pasos esenciales para garantizar la eficacia y precisión de los modelos de aprendizaje automático que se apliquen posteriormente.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "dry_bean_dataset = fetch_ucirepo(id=602) \n",
    "  \n",
    "X = dry_bean_dataset.data.features \n",
    "y = dry_bean_dataset.data.targets \n",
    "y = np.where(y == 'SEKER', 0, y)\n",
    "y = np.where(y == 'BARBUNYA', 1, y)\n",
    "y = np.where(y == 'BOMBAY', 2, y)\n",
    "y = np.where(y == 'CALI', 3, y)\n",
    "y = np.where(y == 'HOROZ', 4, y)\n",
    "y = np.where(y == 'SIRA', 5, y)\n",
    "y = np.where(y == 'DERMASON', 6, y)\n",
    "# Cambiar el tipo de dato de las etiquetas a entero\n",
    "y = y.astype(int)\n",
    "y = y.flatten()\n",
    "\n",
    "data_dry_bean = pd.DataFrame(X, columns=dry_bean_dataset.data.feature_names)\n",
    "data_dry_bean['label'] = y\n",
    "data_dry_bean = data_dry_bean.dropna()\n",
    "X_dry_bean = data_dry_bean.drop(columns=['label']).values\n",
    "y_dry_bean = data_dry_bean['label'].values\n",
    "\n",
    "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "X_train_dry_bean, X_test_dry_bean, y_train_dry_bean, y_test_dry_bean = train_test_split(X_dry_bean, y_dry_bean, test_size=0.2, random_state=42, stratify=y_dry_bean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explicación del Proceso de Preparación y División del Conjunto de Datos de Arroz 'Cammeo' y 'Osmancik'\n",
    "\n",
    "### Objetivo\n",
    "Este proceso detalla los pasos para preparar y dividir un conjunto de datos de variedades de arroz, específicamente 'Cammeo' y 'Osmancik', para su análisis y modelado.\n",
    "\n",
    "### Descripción del Proceso\n",
    "\n",
    "1. **Carga del Conjunto de Datos**: \n",
    "   - Se accede y carga el conjunto de datos de arroz 'Cammeo' y 'Osmancik' desde el repositorio en línea de UCI.\n",
    "\n",
    "2. **Extracción de Características y Etiquetas**: \n",
    "   - Se extraen las características (`X`) y las etiquetas objetivo (`y`) del conjunto de datos. Las características incluyen aspectos físicos y químicos del arroz.\n",
    "\n",
    "3. **Transformación de Etiquetas de Texto a Numéricas**: \n",
    "   - Las etiquetas originales, que son nombres de variedades de arroz, se transforman en valores numéricos para su procesamiento. 'Cammeo' se convierte en 0 y 'Osmancik' en 1.\n",
    "\n",
    "4. **Conversión de Tipo de Dato de Etiquetas**: \n",
    "   - Las etiquetas transformadas se convierten a tipo entero para garantizar la uniformidad en el análisis y en los algoritmos de aprendizaje automático.\n",
    "\n",
    "5. **Creación y Limpieza de un DataFrame de pandas**: \n",
    "   - Se crea un DataFrame con las características y etiquetas numéricas.\n",
    "   - Se eliminan las filas con valores faltantes (NaN) para asegurar la integridad de los datos.\n",
    "\n",
    "6. **Preparación de Datos para Modelado**: \n",
    "   - Se separan las características y las etiquetas para su uso en entrenamiento y pruebas de modelos de aprendizaje automático.\n",
    "\n",
    "7. **División en Conjuntos de Entrenamiento y Prueba**: \n",
    "   - Los datos se dividen en conjuntos de entrenamiento y prueba, típicamente reservando un 20% para pruebas. Esta división permite evaluar la efectividad del modelo en datos no vistos previamente.\n",
    "\n",
    "### Conclusión\n",
    "Este proceso metodológico asegura que el conjunto de datos de arroz 'Cammeo' y 'Osmancik' esté preparado adecuadamente, libre de datos faltantes y con etiquetas claramente definidas, facilitando su uso en aplicaciones de aprendizaje automático para clasificación o análisis detallado.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "rice_cammeo_and_osmancik = fetch_ucirepo(id=545) \n",
    "  \n",
    "# data (as pandas dataframes) \n",
    "X = rice_cammeo_and_osmancik.data.features \n",
    "y = rice_cammeo_and_osmancik.data.targets  \n",
    "labels = np.unique(y)\n",
    "y = np.where(y == 'Cammeo', 0, y)\n",
    "y = np.where(y == 'Osmancik', 1, y)\n",
    "\n",
    "# Cambiar el tipo de dato de las etiquetas a entero\n",
    "y = y.astype(int)\n",
    "y = y.flatten()\n",
    "\n",
    "data_rice = pd.DataFrame(X, columns=rice_cammeo_and_osmancik.data.feature_names)\n",
    "data_rice['label'] = y\n",
    "\n",
    "# Eliminar filas con valores nulos\n",
    "data_rice = data_rice.dropna()\n",
    "X_rice = data_rice.drop(columns=['label']).values\n",
    "\n",
    "# Inicialización del escalador MinMax\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Ajustar el escalador a las características y transformarlas\n",
    "X_rice = scaler.fit_transform(X_rice)\n",
    "\n",
    "y_rice = data_rice['label'].values\n",
    "\n",
    "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "X_train_rice, X_test_rice, y_train_rice, y_test_rice = train_test_split(X_rice, y_rice, test_size=0.2, random_state=42, stratify=y_rice)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clasificador Basado en Estimador de Densidad por Kernels\n",
    "\n",
    "### Descripción General\n",
    "El clasificador utiliza un enfoque basado en el estimador de densidad kernel para determinar la probabilidad de que un conjunto de datos pertenezca a una clase en particular. Este método es útil en situaciones donde las distribuciones de clase son continuas y pueden ser aproximadas por densidades suaves.\n",
    "\n",
    "### Implementación\n",
    "La implementación consta de dos componentes principales:\n",
    "- **Función `kernel_density_estimator`**: Calcula la estimación de densidad kernel para un conjunto de puntos utilizando un conjunto de datos de referencia y un parámetro de ancho de banda.\n",
    "- **Clase `KernelDensityClassifier`**: Inicializa el clasificador con un ancho de banda especificado, aprende las densidades de cada clase en los datos de entrenamiento, y luego utiliza estas densidades para predecir las clases de nuevas observaciones.\n",
    "\n",
    "### Uso del Clasificador\n",
    "Para usar el clasificador, se debe primero entrenarlo con un conjunto de datos etiquetados y luego utilizarlo para hacer predicciones sobre nuevos datos. El entrenamiento se realiza mediante el método `fit`, y las predicciones se generan con el método `predict`.\n",
    "\n",
    "### Consideraciones\n",
    "- La elección del `bandwidth` es crucial para el rendimiento del clasificador.\n",
    "- Es adecuado para datos con distribuciones suaves y continuas.\n",
    "- Es importante asegurar que los datos estén correctamente formateados y preprocesados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimador de densidad kernel\n",
    "def kernel_density_estimator(x, data, bandwidth):\n",
    "    \"\"\"\n",
    "    Calcula la estimación de densidad kernel para un conjunto de puntos.\n",
    "\n",
    "    Args:\n",
    "    x (array-like): Punto o conjunto de puntos para los cuales se calcula la estimación de densidad.\n",
    "    data (array-like): Conjunto de datos de referencia utilizado para la estimación de densidad.\n",
    "    bandwidth (float): Ancho de banda del kernel, controla la suavidad de la estimación de densidad.\n",
    "\n",
    "    Returns:\n",
    "    array-like: Estimación de densidad para cada punto en `x`.\n",
    "    \"\"\"\n",
    "    n = len(data)  # Número de puntos en el conjunto de datos de referencia\n",
    "    # Calcula la densidad para cada punto en 'x' utilizando un kernel Gaussiano\n",
    "    densities = np.sum(np.exp(-0.5 * ((x - data) / bandwidth)**2) / (np.sqrt(2 * np.pi) * bandwidth), axis=1)\n",
    "    return densities / n  # Normaliza la densidad por el número de puntos en 'data'\n",
    "\n",
    "# Clasificador basado en estimador de densidad kernel ajustado\n",
    "class KernelDensityClassifier:\n",
    "    def __init__(self, bandwidth=1.0):\n",
    "        \"\"\"\n",
    "        Inicializa el clasificador basado en estimador de densidad kernel.\n",
    "\n",
    "        Args:\n",
    "        bandwidth (float): Ancho de banda para el estimador de densidad kernel.\n",
    "        \"\"\"\n",
    "        self.bandwidth = bandwidth  # Ancho de banda para el kernel\n",
    "        self.classes_ = None  # Almacenará las clases únicas en los datos\n",
    "        self.densities_ = None  # Almacenará las densidades por clase\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Entrena el clasificador utilizando los datos proporcionados.\n",
    "\n",
    "        Args:\n",
    "        X (array-like): Datos de entrenamiento, donde cada fila es una observación.\n",
    "        y (array-like): Etiquetas de clase para cada observación en X.\n",
    "        \"\"\"\n",
    "        self.classes_ = np.unique(y)  # Encuentra las clases únicas\n",
    "        self.densities_ = [None] * len(self.classes_)  # Inicializa la lista de densidades\n",
    "        for i, cls in enumerate(self.classes_):  # Para cada clase...\n",
    "            self.densities_[i] = X[y == cls]  # ...almacena los datos correspondientes a esa clase\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Predice las etiquetas de clase para las observaciones dadas.\n",
    "\n",
    "        Args:\n",
    "        X (array-like): Datos de prueba, donde cada fila es una observación.\n",
    "\n",
    "        Returns:\n",
    "        np.ndarray: Etiquetas de clase predichas para cada observación en X.\n",
    "        \"\"\"\n",
    "        probs = np.zeros((X.shape[0], len(self.classes_)))  # Inicializa matriz de probabilidades\n",
    "        for i, class_data in enumerate(self.densities_):  # Para cada conjunto de datos de clase...\n",
    "            for j, x in enumerate(X):  # ...y para cada punto en 'X'...\n",
    "                # ...calcula la suma de las densidades kernel para ese punto y esa clase\n",
    "                probs[j, i] = kernel_density_estimator(x, class_data, self.bandwidth).sum()\n",
    "        class_indices = np.argmax(probs, axis=1)  # Encuentra la clase con la mayor probabilidad\n",
    "        return self.classes_[class_indices]  # Devuelve las clases predichas\n",
    "    \n",
    "    # Método para obtener los parámetros del clasificador\n",
    "    def get_params(self, deep=True):\n",
    "        return {\"bandwidth\": self.bandwidth}\n",
    "\n",
    "    # Método para establecer los parámetros del clasificador\n",
    "    def set_params(self, **parameters):\n",
    "        for parameter, value in parameters.items():\n",
    "            setattr(self, parameter, value)\n",
    "        return self"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clasificador CART (Árboles de Clasificación y Regresión)\n",
    "\n",
    "### Descripción General\n",
    "El clasificador CART es una técnica de aprendizaje supervisado utilizada para construir árboles de decisión, que modelan decisiones y sus posibles consecuencias como un árbol. Esta metodología es efectiva tanto para la clasificación como para la regresión y es útil para problemas donde las relaciones entre los parámetros no son lineales o son desconocidas.\n",
    "\n",
    "### Implementación\n",
    "La implementación de CART en Python se realiza a través de una clase que envuelve el estimador de árbol de decisión. Consta de:\n",
    "- Una inicialización que configura el árbol con parámetros como el ancho de banda para la poda.\n",
    "- Un método de entrenamiento que adapta el árbol a los datos proporcionados.\n",
    "- Un método de predicción que utiliza el árbol entrenado para realizar predicciones sobre nuevos conjuntos de datos.\n",
    "\n",
    "### Uso del Clasificador\n",
    "Para utilizar el clasificador CART, se prepara un conjunto de datos con características y etiquetas, se entrena el modelo con estos datos y luego se usan los métodos implementados para hacer predicciones. Es crucial realizar un preprocesamiento adecuado de los datos y seleccionar el parámetro de complejidad adecuado para optimizar el rendimiento.\n",
    "\n",
    "### Consideraciones\n",
    "- Es importante elegir correctamente el parámetro de complejidad para evitar sobreajustes o subajustes.\n",
    "- El clasificador CART es adecuado para interpretar modelos y para manejar datos categóricos y continuos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CARTClassifier(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, ccp_alpha=0.0):\n",
    "        \"\"\"\n",
    "        Inicializa el clasificador CART.\n",
    "\n",
    "        Parameters:\n",
    "        ccp_alpha (float): Parámetro de complejidad (alpha) para la poda de costo-complejidad.\n",
    "                           Un valor más alto de alpha resultará en más nodos siendo podados.\n",
    "        \"\"\"\n",
    "        self.ccp_alpha = ccp_alpha\n",
    "        self.tree = DecisionTreeClassifier(ccp_alpha=ccp_alpha)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Entrena el clasificador CART usando los datos de entrenamiento.\n",
    "\n",
    "        Parameters:\n",
    "        X (array-like): Matriz de características de entrenamiento.\n",
    "        y (array-like): Vector de etiquetas objetivo.\n",
    "        \"\"\"\n",
    "        self.tree.fit(X, y)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Realiza predicciones utilizando el árbol de decisión entrenado.\n",
    "\n",
    "        Parameters:\n",
    "        X (array-like): Matriz de características de los datos a predecir.\n",
    "\n",
    "        Returns:\n",
    "        array-like: Vector de predicciones para cada observación en X.\n",
    "        \"\"\"\n",
    "        return self.tree.predict(X)\n",
    "\n",
    "    def get_params(self, deep=True):\n",
    "        \"\"\"\n",
    "        Obtiene los parámetros del clasificador.\n",
    "\n",
    "        Returns:\n",
    "        dict: Un diccionario de los parámetros del clasificador.\n",
    "        \"\"\"\n",
    "        return {'ccp_alpha': self.ccp_alpha}\n",
    "\n",
    "    def set_params(self, **params):\n",
    "        \"\"\"\n",
    "        Establece los parámetros del clasificador.\n",
    "\n",
    "        Parameters:\n",
    "        params (dict): Un diccionario de parámetros a establecer.\n",
    "        \"\"\"\n",
    "        self.ccp_alpha = params.get('ccp_alpha', self.ccp_alpha)\n",
    "        self.tree = DecisionTreeClassifier(ccp_alpha=self.ccp_alpha)\n",
    "        return self\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clasificador de Bosques Aleatorios\n",
    "\n",
    "### Descripción General\n",
    "Los Bosques Aleatorios son un método de ensamblaje que construye múltiples árboles de decisión y los combina para obtener una predicción más precisa y robusta. Este método es efectivo para lidiar con sobreajustes y proporciona una mejor generalización.\n",
    "\n",
    "### Implementación\n",
    "El clasificador de Bosques Aleatorios se implementa utilizando una clase que maneja un conjunto de árboles de decisión. Esta implementación incluye:\n",
    "- Configuración del número de árboles, la cantidad de variables a considerar en cada división y si se debe utilizar el remuestreo bootstrap.\n",
    "- Un método de entrenamiento para construir el bosque a partir del conjunto de datos de entrenamiento.\n",
    "- Un método de predicción para estimar la clase de observaciones no vistas basándose en la votación mayoritaria de los árboles.\n",
    "\n",
    "### Uso del Clasificador\n",
    "El clasificador de Bosques Aleatorios se utiliza entrenando primero el modelo con datos etiquetados y luego aplicándolo a nuevos datos para realizar predicciones. La validación cruzada y la búsqueda de parámetros óptimos son prácticas recomendadas para lograr un rendimiento óptimo.\n",
    "\n",
    "### Consideraciones\n",
    "- La selección de hiperparámetros como la cantidad de árboles y la profundidad máxima es crucial para el rendimiento del modelo.\n",
    "- Los Bosques Aleatorios son eficaces para problemas de clasificación multiclase y para conjuntos de datos con un gran número de características."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomForestClassifierOptimized(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, n_estimators=100, max_features='auto', max_samples=None):\n",
    "        \"\"\"\n",
    "        Inicializa el clasificador de Bosques Aleatorios.\n",
    "        \n",
    "        Parameters:\n",
    "        n_estimators (int): Número de árboles en el bosque.\n",
    "        max_features (int, float, string or None): Número de características a considerar al buscar la mejor división.\n",
    "        max_samples (int or float): Número de muestras a utilizar para entrenar cada árbol del bosque.\n",
    "        \"\"\"\n",
    "        self.n_estimators = n_estimators\n",
    "        self.max_features = max_features\n",
    "        self.max_samples = max_samples\n",
    "        self.rf = RandomForestClassifier(n_estimators=n_estimators, max_features=max_features, max_samples=max_samples)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Entrena el clasificador de Bosques Aleatorios utilizando los datos de entrenamiento.\n",
    "        \n",
    "        Parameters:\n",
    "        X (array-like): Matriz de características de entrenamiento.\n",
    "        y (array-like): Vector de etiquetas objetivo.\n",
    "        \"\"\"\n",
    "        self.rf.fit(X, y)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Realiza predicciones utilizando el bosque de decisión entrenado.\n",
    "        \n",
    "        Parameters:\n",
    "        X (array-like): Matriz de características de los datos a predecir.\n",
    "        \n",
    "        Returns:\n",
    "        array-like: Vector de predicciones para cada observación en X.\n",
    "        \"\"\"\n",
    "        return self.rf.predict(X)\n",
    "\n",
    "    def get_params(self, deep=True):\n",
    "        \"\"\"\n",
    "        Obtiene los parámetros del clasificador.\n",
    "        \n",
    "        Returns:\n",
    "        dict: Un diccionario de los parámetros del clasificador.\n",
    "        \"\"\"\n",
    "        return {'n_estimators': self.n_estimators, 'max_features': self.max_features}\n",
    "\n",
    "    def set_params(self, **params):\n",
    "        \"\"\"\n",
    "        Establece los parámetros del clasificador.\n",
    "        \n",
    "        Parameters:\n",
    "        params (dict): Un diccionario de parámetros a establecer.\n",
    "        \"\"\"\n",
    "        self.n_estimators = params.get('n_estimators', self.n_estimators)\n",
    "        self.max_features = params.get('max_features', self.max_features)\n",
    "        self.rf = RandomForestClassifier(n_estimators=self.n_estimators, max_features=self.max_features)\n",
    "        return self"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clasificador de KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import Counter\n",
    "from scipy.stats import mode\n",
    "\n",
    "class KNNClassifier(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, n_neighbors=5):\n",
    "        \"\"\"\n",
    "        Inicializa el clasificador KNN con el número de vecinos especificado.\n",
    "        \"\"\"\n",
    "        self.n_neighbors = n_neighbors\n",
    "        self.X_train = None\n",
    "        self.y_train = None\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Ajusta el clasificador al conjunto de datos de entrenamiento.\n",
    "        \n",
    "        Parámetros:\n",
    "        X : array-like, shape (n_samples, n_features)\n",
    "            Las muestras de entrenamiento.\n",
    "        y : array-like, shape (n_samples,)\n",
    "            Las etiquetas de clase para las muestras de entrenamiento.\n",
    "        \"\"\"\n",
    "        self.X_train = X\n",
    "        self.y_train = y\n",
    "        # Guardar las etiquetas de clase vistas durante el ajuste\n",
    "        self.classes_ = np.unique(y)\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Realiza predicciones para las muestras de entrada.\n",
    "        \n",
    "        Parámetros:\n",
    "        X : array-like, shape (n_samples, n_features)\n",
    "            Las muestras de prueba.\n",
    "        \n",
    "        Retorna:\n",
    "        y_pred : array-like, shape (n_samples,)\n",
    "            Las etiquetas de clase predichas para las muestras de prueba.\n",
    "        \"\"\"\n",
    "        y_pred = [self._predict(x) for x in X]\n",
    "        return np.array(y_pred)\n",
    "    \n",
    "    def _predict(self, x):\n",
    "        \"\"\"\n",
    "        Realiza una predicción para una sola muestra de entrada.\n",
    "        \n",
    "        Parámetros:\n",
    "        x : array-like, shape (n_features,)\n",
    "            Una sola muestra de prueba.\n",
    "        \n",
    "        Retorna:\n",
    "        y_pred : int\n",
    "            La etiqueta de clase predicha para la muestra de prueba.\n",
    "        \"\"\"\n",
    "        # Calcular las distancias euclidianas desde esta muestra a todas las muestras de entrenamiento\n",
    "        distances = [self._euclidean_distance(x, x_train) for x_train in self.X_train]\n",
    "        \n",
    "        # Obtener los índices de los k vecinos más cercanos\n",
    "        k_indices = np.argsort(distances)[:self.n_neighbors]\n",
    "        \n",
    "        # Obtener las etiquetas de los k vecinos más cercanos\n",
    "        k_nearest_labels = [self.y_train[i] for i in k_indices]\n",
    "        \n",
    "        # Determinar la clase más común entre los vecinos\n",
    "        mode_result = mode(k_nearest_labels, keepdims=False)\n",
    "        most_common = mode_result.mode\n",
    "        if np.isscalar(most_common):\n",
    "            return most_common\n",
    "        else:\n",
    "            return most_common[0]\n",
    "    \n",
    "    def _euclidean_distance(self, x1, x2):\n",
    "        \"\"\"\n",
    "        Calcula la distancia euclidiana entre dos vectores.\n",
    "        \n",
    "        Parámetros:\n",
    "        x1 : array-like, shape (n_features,)\n",
    "            Primer vector.\n",
    "        x2 : array-like, shape (n_features,)\n",
    "            Segundo vector.\n",
    "        \n",
    "        Retorna:\n",
    "        distance : float\n",
    "            La distancia euclidiana entre los dos vectores.\n",
    "        \"\"\"\n",
    "        return np.sqrt(np.sum((x1 - x2) ** 2))\n",
    "    \n",
    "    def get_params(self, deep=True):\n",
    "        \"\"\"\n",
    "        Obtiene los parámetros para este estimador.\n",
    "        \n",
    "        Parámetros:\n",
    "        deep (bool) : Si es True, devolverá los parámetros para este estimador y los subobjetos que son estimadores.\n",
    "        \n",
    "        Retorna:\n",
    "        params : dict\n",
    "            Los parámetros del estimador.\n",
    "        \"\"\"\n",
    "        return {'n_neighbors': self.n_neighbors}\n",
    "    \n",
    "    def set_params(self, **params):\n",
    "        \"\"\"\n",
    "        Establece los parámetros de este estimador.\n",
    "        \n",
    "        Parámetros:\n",
    "        params : dict\n",
    "            Los parámetros a establecer.\n",
    "        \"\"\"\n",
    "        n_neighbors = params.get('n_neighbors')\n",
    "        if n_neighbors is not None:\n",
    "            self.n_neighbors = n_neighbors\n",
    "        return self"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clasificador SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SVMOptimizer(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, C=1.0, kernel='rbf', gamma='scale'):\n",
    "        \"\"\"\n",
    "        Inicializa la máquina de soporte vectorial con los parámetros especificados.\n",
    "        \n",
    "        Parameters:\n",
    "        C (float): Parámetro de penalización de la función de error.\n",
    "        kernel (str): Especifica el tipo de kernel a utilizar en el algoritmo.\n",
    "        gamma (str or float): Coeficiente para el kernel 'rbf', 'poly' y 'sigmoid'.\n",
    "        \"\"\"\n",
    "        self.C = C\n",
    "        self.kernel = kernel\n",
    "        self.gamma = gamma\n",
    "        self.svm = SVC(C=C, kernel=kernel, gamma=gamma)\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Entrena el clasificador SVM utilizando los datos de entrenamiento.\n",
    "        \n",
    "        Parameters:\n",
    "        X (array-like): Matriz de características de entrenamiento.\n",
    "        y (array-like): Vector de etiquetas objetivo.\n",
    "        \"\"\"\n",
    "        self.svm.fit(X, y)\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Realiza predicciones utilizando el clasificador SVM entrenado.\n",
    "        \n",
    "        Parameters:\n",
    "        X (array-like): Matriz de características de los datos a predecir.\n",
    "        \n",
    "        Returns:\n",
    "        array-like: Vector de predicciones para cada observación en X.\n",
    "        \"\"\"\n",
    "        return self.svm.predict(X)\n",
    "    \n",
    "    def get_params(self, deep=True):\n",
    "        \"\"\"\n",
    "        Obtiene los parámetros del clasificador.\n",
    "        \n",
    "        Returns:\n",
    "        dict: Un diccionario de los parámetros del clasificador.\n",
    "        \"\"\"\n",
    "        return {'C': self.C, 'kernel': self.kernel, 'gamma': self.gamma}\n",
    "    \n",
    "    def set_params(self, **parameters):\n",
    "        \"\"\"\n",
    "        Establece los parámetros del clasificador.\n",
    "        \n",
    "        Parameters:\n",
    "        parameters (dict): Un diccionario de parámetros a establecer.\n",
    "        \"\"\"\n",
    "        for parameter, value in parameters.items():\n",
    "            setattr(self, parameter, value)\n",
    "        self.svm = SVC(C=self.C, kernel=self.kernel, gamma=self.gamma)\n",
    "        return self\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenamiento del Clasificador y selección de Parámetros con Validación Cruzada\n",
    "\n",
    "### Objetivo\n",
    "El fragmento de código describe un proceso para seleccionar de manera óptima los parámetros de un clasificador basado en el estimador de densidad kernel, utilizando la técnica de validación cruzada.\n",
    "\n",
    "### Procedimiento\n",
    "1. **Definición de Parámetros a Probar**: Se especifica un conjunto de valores posibles para el parámetro 'bandwidth' del clasificador. Estos valores varían en un rango predefinido y son los candidatos para ser evaluados.\n",
    "\n",
    "2. **Uso de GridSearchCV para la Optimización de Parámetros**: \n",
    "   - Se emplea GridSearchCV, una herramienta que automatiza el proceso de ajuste de parámetros, para evaluar todas las combinaciones posibles de los valores de 'bandwidth'.\n",
    "   - Se utiliza una validación cruzada de 5 pliegues (cv=5), lo que significa que los datos se dividen en 5 conjuntos, y el modelo se entrena y valida 5 veces, cada vez con un conjunto diferente como prueba y el resto como entrenamiento.\n",
    "\n",
    "3. **Evaluación Basada en la Métrica F1**: La selección se realiza buscando maximizar la puntuación F1, que es una medida que combina la precisión y el recall.\n",
    "\n",
    "4. **Medición del Tiempo de Ejecución**: Se registra el tiempo que toma realizar todo el proceso de ajuste de parámetros.\n",
    "\n",
    "5. **Resultados**:\n",
    "   - Al finalizar, se obtiene el mejor valor de 'bandwidth' (aquel que maximiza la puntuación F1 en la validación cruzada).\n",
    "   - Se muestra la mejor puntuación F1 alcanzada y el tiempo total de ejecución.\n",
    "\n",
    "### Conclusión\n",
    "Este enfoque permite identificar el mejor parámetro 'bandwidth' para el clasificador, garantizando una selección objetiva y basada en el rendimiento del modelo en diferentes subconjuntos de datos. Además, proporciona información valiosa sobre la complejidad computacional del proceso de selección de parámetros.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pruebas con KDE\n",
    "\n",
    "### Para el conjunto de datos de cáncer de mama de Wisconsin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definición de los parámetros a probar\n",
    "param_grid = {'bandwidth': [0.5, 1.0, 1.5, 2.0, 2.5, 3.0, 3.3, 3.35, 4.0, 4.5, 5.0]}\n",
    "\n",
    "# Inicialización de GridSearchCV con validación cruzada de 5 particiones (20% de los datos para prueba)\n",
    "grid_search = GridSearchCV(KernelDensityClassifier(), param_grid, cv=5, scoring='f1')\n",
    "\n",
    "# Medición del tiempo de \"preparación\" y ajuste de parámetros\n",
    "start_time = time.time()\n",
    "grid_search.fit(X_train_breast_cancer, y_train_breast_cancer)\n",
    "end_time = time.time()\n",
    "\n",
    "# Tiempo total utilizado en el proceso\n",
    "total_time = end_time - start_time\n",
    "\n",
    "# Resultados de GridSearchCV\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores parámetros (Breast Cancer - KDE): {'bandwidth': 3.3}\n",
      "Mejor puntuación F1 (Breast Cancer - KDE): 0.9187134374634376\n",
      "Tiempo total de preparación y ajuste de parámetros (Breast Cancer - KDE): 1.0492079257965088\n"
     ]
    }
   ],
   "source": [
    "print(\"Mejores parámetros (Breast Cancer - KDE):\", best_params)\n",
    "print(\"Mejor puntuación F1 (Breast Cancer - KDE):\", best_score)\n",
    "print(\"Tiempo total de preparación y ajuste de parámetros (Breast Cancer - KDE):\", total_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener el mejor clasificador\n",
    "best_clf_kde_breast = grid_search.best_estimator_\n",
    "\n",
    "# Entrenar el mejor clasificador\n",
    "best_clf_kde_breast.fit(X_train_breast_cancer, y_train_breast_cancer)\n",
    "\n",
    "# Predecir las etiquetas de clase para los datos de prueba\n",
    "y_pred_kde_breast = best_clf_kde_breast.predict(X_test_breast_cancer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "breast_cancer_results_kde = {}\n",
    "breast_cancer_results_kde['accuracy'] = accuracy_score(y_test_breast_cancer, y_pred_kde_breast)\n",
    "breast_cancer_results_kde['f1'] = f1_score(y_test_breast_cancer, y_pred_kde_breast)\n",
    "breast_cancer_results_kde['recall'] = recall_score(y_test_breast_cancer, y_pred_kde_breast)\n",
    "breast_cancer_results_kde['precision'] = precision_score(y_test_breast_cancer, y_pred_kde_breast)\n",
    "breast_cancer_results_kde[\"time\"] = total_time\n",
    "breast_cancer_results_kde[\"best_params\"] = f\"h = {best_params}\"\n",
    "breast_cancer_results_kde[\"confusion_matrix\"] = confusion_matrix(y_test_breast_cancer, y_pred_kde_breast)\n",
    "\n",
    "with open('breast_cancer_results_kde.txt', 'w') as file:\n",
    "    file.write(str(breast_cancer_results_kde))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Para el dataset del arroz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definición de los parámetros a probar\n",
    "param_grid = {'bandwidth': [0.5, 1.0, 1.1, 1.2, 1.3, 1.5, 2.0, 2.5, 3.0, 4.0, 4.5, 5.0]}\n",
    "\n",
    "# Inicialización de GridSearchCV con validación cruzada de 5 particiones (20% de los datos para prueba)\n",
    "grid_search = GridSearchCV(KernelDensityClassifier(), param_grid, cv=5, scoring='f1')\n",
    "\n",
    "# Medición del tiempo de \"preparación\" y ajuste de parámetros\n",
    "start_time = time.time()\n",
    "grid_search.fit(X_train_rice, y_train_rice)\n",
    "end_time = time.time()\n",
    "\n",
    "# Tiempo total utilizado en el proceso\n",
    "total_time = end_time - start_time\n",
    "\n",
    "# Resultados de GridSearchCV\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores parámetros (Breast Cancer - KDE): {'bandwidth': 1.3}\n",
      "Mejor puntuación F1 (Breast Cancer - KDE): 0.9329069935147014\n",
      "Tiempo total de preparación y ajuste de parámetros (Breast Cancer - KDE): 10.27276611328125\n"
     ]
    }
   ],
   "source": [
    "print(\"Mejores parámetros (Breast Cancer - KDE):\", best_params)\n",
    "print(\"Mejor puntuación F1 (Breast Cancer - KDE):\", best_score)\n",
    "print(\"Tiempo total de preparación y ajuste de parámetros (Breast Cancer - KDE):\", total_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener el mejor clasificador\n",
    "best_clf_kde_rice = grid_search.best_estimator_\n",
    "\n",
    "# Entrenar el mejor clasificador\n",
    "best_clf_kde_rice.fit(X_train_rice, y_train_rice)\n",
    "\n",
    "# Predecir las etiquetas de clase para los datos de prueba\n",
    "y_pred_kde_rice = best_clf_kde_rice.predict(X_test_rice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "rice_results_kde = {}\n",
    "rice_results_kde['accuracy'] = accuracy_score(y_test_rice, y_pred_kde_rice)\n",
    "rice_results_kde['f1'] = f1_score(y_test_rice, y_pred_kde_rice)\n",
    "rice_results_kde['recall'] = recall_score(y_test_rice, y_pred_kde_rice)\n",
    "rice_results_kde['precision'] = precision_score(y_test_rice, y_pred_kde_rice)\n",
    "rice_results_kde[\"time\"] = total_time\n",
    "rice_results_kde[\"best_params\"] = f\"h = {best_params}\"\n",
    "rice_results_kde[\"confusion_matrix\"] = confusion_matrix(y_test_rice, y_pred_kde_rice)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Para el dataset de frijoles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definición de los parámetros a probar\n",
    "param_grid = {'bandwidth': [1.0, 2.0, 3.0, 4.0, 5.0]}\n",
    "\n",
    "# Inicialización de GridSearchCV con validación cruzada de 5 particiones (20% de los datos para prueba)\n",
    "grid_search = GridSearchCV(KernelDensityClassifier(), param_grid, cv=5, scoring='f1_macro')\n",
    "\n",
    "# Medición del tiempo de \"preparación\" y ajuste de parámetros\n",
    "start_time = time.time()\n",
    "grid_search.fit(X_train_dry_bean, y_train_dry_bean)\n",
    "end_time = time.time()\n",
    "\n",
    "# Tiempo total utilizado en el proceso\n",
    "total_time = end_time - start_time\n",
    "\n",
    "# Resultados de GridSearchCV\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores parámetros (Breast Cancer - KDE): {'bandwidth': 1.0}\n",
      "Mejor puntuación F1 (Breast Cancer - KDE): 0.8591393271627868\n",
      "Tiempo total de preparación y ajuste de parámetros (Breast Cancer - KDE): 193.34835147857666\n"
     ]
    }
   ],
   "source": [
    "print(\"Mejores parámetros (Breast Cancer - KDE):\", best_params)\n",
    "print(\"Mejor puntuación F1 (Breast Cancer - KDE):\", best_score)\n",
    "print(\"Tiempo total de preparación y ajuste de parámetros (Breast Cancer - KDE):\", total_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener el mejor clasificador\n",
    "best_clf_kde_dry_bean = grid_search.best_estimator_\n",
    "\n",
    "# Entrenar el mejor clasificador\n",
    "best_clf_kde_dry_bean.fit(X_train_dry_bean, y_train_dry_bean)\n",
    "\n",
    "# Predecir las etiquetas de clase para los datos de prueba\n",
    "y_pred_kde_dry_bean = best_clf_kde_dry_bean.predict(X_test_dry_bean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "dry_bean_results_kde = classification_report(y_test_dry_bean, y_pred_kde_dry_bean, output_dict=True)\n",
    "dry_bean_results_kde['accuracy'] = accuracy_score(y_test_dry_bean, y_pred_kde_dry_bean)\n",
    "dry_bean_results_kde[\"time\"] = total_time\n",
    "dry_bean_results_kde[\"best_params\"] = f\"h = {best_params}\"\n",
    "dry_bean_results_kde[\"confusion_matrix\"] = confusion_matrix(y_test_dry_bean, y_pred_kde_dry_bean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pruebas con CART\n",
    "\n",
    "### Para el conjunto de datos de cáncer de mama de Wisconsin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definición de los parámetros a probar\n",
    "param_grid = {'ccp_alpha': [0.00001, 0.0004, 0.0003, 0.0005, 0.0008, 0.001, 0.01, 0.1]}\n",
    "# Inicialización de GridSearchCV con validación cruzada de 5 particiones (20% de los datos para prueba)\n",
    "grid_search = GridSearchCV(CARTClassifier(), param_grid, cv=5)\n",
    "\n",
    "# Medición del tiempo de \"preparación\" y ajuste de parámetros\n",
    "start_time = time.time()\n",
    "grid_search.fit(X_train_breast_cancer, y_train_breast_cancer)\n",
    "end_time = time.time()\n",
    "\n",
    "# Tiempo total utilizado en el proceso\n",
    "total_time = end_time - start_time\n",
    "\n",
    "# Resultados de GridSearchCV\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores parámetros (Breast Cancer - CART): {'ccp_alpha': 0.0003}\n",
      "Mejor puntuación F1 (Breast Cancer - CART): 0.9560467055879901\n",
      "Tiempo total de preparación y ajuste de parámetros (Breast Cancer - CART): 0.11925697326660156\n"
     ]
    }
   ],
   "source": [
    "print(\"Mejores parámetros (Breast Cancer - CART):\", best_params)\n",
    "print(\"Mejor puntuación F1 (Breast Cancer - CART):\", best_score)\n",
    "print(\"Tiempo total de preparación y ajuste de parámetros (Breast Cancer - CART):\", total_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener el mejor clasificador\n",
    "best_clf_cart_breast = grid_search.best_estimator_\n",
    "\n",
    "# Entrenar el mejor clasificador\n",
    "best_clf_cart_breast.fit(X_train_breast_cancer, y_train_breast_cancer)\n",
    "\n",
    "# Predecir las etiquetas de clase para los datos de prueba\n",
    "y_pred_cart_breast = best_clf_cart_breast.predict(X_test_breast_cancer)\n",
    "\n",
    "breast_cancer_results_cart = {}\n",
    "breast_cancer_results_cart['accuracy'] = accuracy_score(y_test_breast_cancer, y_pred_cart_breast)\n",
    "breast_cancer_results_cart['f1'] = f1_score(y_test_breast_cancer, y_pred_cart_breast)\n",
    "breast_cancer_results_cart['recall'] = recall_score(y_test_breast_cancer, y_pred_cart_breast)\n",
    "breast_cancer_results_cart['precision'] = precision_score(y_test_breast_cancer, y_pred_cart_breast)\n",
    "breast_cancer_results_cart[\"time\"] = total_time\n",
    "breast_cancer_results_cart[\"best_params\"] = f\"cp = {best_params}\"\n",
    "breast_cancer_results_cart[\"confusion_matrix\"] = confusion_matrix(y_test_breast_cancer, y_pred_cart_breast)\n",
    "\n",
    "with open('breast_cancer_results_cart.txt', 'w') as file:\n",
    "    file.write(str(breast_cancer_results_cart))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Para el conjunto de datos de arroz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definición de los parámetros a probar\n",
    "param_grid = {'ccp_alpha': [0.00001, 0.0004, 0.0003, 0.0005, 0.0008, 0.001, 0.002, 0.003, 0.005, 0.01, 0.015, 0.1]}\n",
    "# Inicialización de GridSearchCV con validación cruzada de 5 particiones (20% de los datos para prueba)\n",
    "grid_search = GridSearchCV(CARTClassifier(), param_grid, cv=5)\n",
    "\n",
    "# Medición del tiempo de \"preparación\" y ajuste de parámetros\n",
    "start_time = time.time()\n",
    "grid_search.fit(X_train_rice, y_train_rice)\n",
    "end_time = time.time()\n",
    "\n",
    "# Tiempo total utilizado en el proceso\n",
    "total_time = end_time - start_time\n",
    "\n",
    "# Resultados de GridSearchCV\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores parámetros (Rice - CART): {'ccp_alpha': 0.002}\n",
      "Mejor puntuación F1 (Rice - CART): 0.9288045438638994\n",
      "Tiempo total de preparación y ajuste de parámetros (Rice - CART): 2.3557820320129395\n"
     ]
    }
   ],
   "source": [
    "print(\"Mejores parámetros (Rice - CART):\", best_params)\n",
    "print(\"Mejor puntuación F1 (Rice - CART):\", best_score)\n",
    "print(\"Tiempo total de preparación y ajuste de parámetros (Rice - CART):\", total_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener el mejor clasificador\n",
    "best_clf_cart_rice = grid_search.best_estimator_\n",
    "\n",
    "# Entrenar el mejor clasificador\n",
    "best_clf_cart_rice.fit(X_train_rice, y_train_rice)\n",
    "\n",
    "# Predecir las etiquetas de clase para los datos de prueba\n",
    "y_pred_cart_rice = best_clf_cart_rice.predict(X_test_rice)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "rice_results_cart = {}\n",
    "rice_results_cart['accuracy'] = accuracy_score(y_test_rice, y_pred_cart_rice)\n",
    "rice_results_cart['f1'] = f1_score(y_test_rice, y_pred_cart_rice)\n",
    "rice_results_cart['recall'] = recall_score(y_test_rice, y_pred_cart_rice)\n",
    "rice_results_cart['precision'] = precision_score(y_test_rice, y_pred_cart_rice)\n",
    "rice_results_cart[\"time\"] = total_time\n",
    "rice_results_cart[\"best_params\"] = f\"cp = {best_params}\"\n",
    "rice_results_cart[\"confusion_matrix\"] = confusion_matrix(y_test_rice, y_pred_cart_rice)\n",
    "\n",
    "with open('rice_results_cart.txt', 'w') as file:\n",
    "    file.write(str(rice_results_cart))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Para el dataset de frijoles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definición de los parámetros a probar\n",
    "param_grid = {'ccp_alpha': [0.00001, 0.0004, 0.0003, 0.0005, 0.0008, 0.001, 0.002, 0.003, 0.005, 0.05, 0.01, 0.015, 0.1]}\n",
    "# Inicialización de GridSearchCV con validación cruzada de 5 particiones (20% de los datos para prueba)\n",
    "grid_search = GridSearchCV(CARTClassifier(), param_grid, cv=5)\n",
    "\n",
    "# Medición del tiempo de \"preparación\" y ajuste de parámetros\n",
    "start_time = time.time()\n",
    "grid_search.fit(X_dry_bean, y_dry_bean)\n",
    "end_time = time.time()\n",
    "\n",
    "# Tiempo total utilizado en el proceso\n",
    "total_time = end_time - start_time\n",
    "\n",
    "# Resultados de GridSearchCV\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores parámetros (Beans - CART): {'ccp_alpha': 0.015}\n",
      "Mejor puntuación F1 (Beans - CART): 0.7560237538933455\n",
      "Tiempo total de preparación y ajuste de parámetros (Beans - CART): 42.28352093696594\n"
     ]
    }
   ],
   "source": [
    "print(\"Mejores parámetros (Beans - CART):\", best_params)\n",
    "print(\"Mejor puntuación F1 (Beans - CART):\", best_score)\n",
    "print(\"Tiempo total de preparación y ajuste de parámetros (Beans - CART):\", total_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener el mejor clasificador\n",
    "best_clf_cart_dry_bean = grid_search.best_estimator_\n",
    "\n",
    "# Entrenar el mejor clasificador\n",
    "best_clf_cart_dry_bean.fit(X_train_dry_bean, y_train_dry_bean)\n",
    "\n",
    "# Predecir las etiquetas de clase para los datos de prueba\n",
    "y_pred_cart_dry_bean = best_clf_cart_dry_bean.predict(X_test_dry_bean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resultados de clasificación\n",
    "dry_bean_results_cart = classification_report(y_test_dry_bean, y_pred_cart_dry_bean, output_dict=True)\n",
    "dry_bean_results_cart['accuracy'] = accuracy_score(y_test_dry_bean, y_pred_cart_dry_bean)\n",
    "dry_bean_results_cart[\"time\"] = total_time\n",
    "dry_bean_results_cart[\"best_params\"] = f\"cp = {best_params}\"\n",
    "dry_bean_results_cart[\"confusion_matrix\"] = confusion_matrix(y_test_dry_bean, y_pred_cart_dry_bean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pruebas con RandomForest\n",
    "\n",
    "### Para el conjunto de datos de cáncer de mama de Wisconsin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_distributions = {\n",
    "    'n_estimators': [10, 50, 100, 200],\n",
    "    'max_features': ['sqrt', 'log2', None] + list(np.arange(0.1, 1.1, 0.1)),\n",
    "    'max_samples': [0.1, 0.5, 0.6, 0.7, 0.8, 0.9, None]  # O un rango de valores que consideres adecuados\n",
    "}\n",
    "\n",
    "random_search = RandomizedSearchCV(RandomForestClassifierOptimized(), param_distributions, n_iter=100, cv=5, random_state=42)\n",
    "\n",
    "# Medición del tiempo de \"preparación\" y ajuste de parámetros\n",
    "start_time = time.time()\n",
    "random_search.fit(X_train_breast_cancer, y_train_breast_cancer)\n",
    "end_time = time.time()\n",
    "\n",
    "# Tiempo total utilizado en el proceso\n",
    "total_time = end_time - start_time\n",
    "\n",
    "# Resultados de RandomizedSearchCV\n",
    "best_params = random_search.best_params_\n",
    "best_score = random_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores parámetros (Breast Cancer - RF): {'n_estimators': 100, 'max_samples': 0.5, 'max_features': 0.1}\n",
      "Mejor puntuación F1 (Breast Cancer - RF): 0.9780316930775645\n",
      "Tiempo total de preparación y ajuste de parámetros (Breast Cancer - RF): 78.48414897918701\n"
     ]
    }
   ],
   "source": [
    "print(\"Mejores parámetros (Breast Cancer - RF):\", best_params)\n",
    "print(\"Mejor puntuación F1 (Breast Cancer - RF):\", best_score)\n",
    "print(\"Tiempo total de preparación y ajuste de parámetros (Breast Cancer - RF):\", total_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener el mejor clasificador\n",
    "best_clf_rf_breast = random_search.best_estimator_\n",
    "\n",
    "# Entrenar el mejor clasificador\n",
    "best_clf_rf_breast.fit(X_train_breast_cancer, y_train_breast_cancer)\n",
    "\n",
    "# Predecir las etiquetas de clase para los datos de prueba\n",
    "y_pred_rf_breast = best_clf_rf_breast.predict(X_test_breast_cancer)\n",
    "\n",
    "breast_cancer_results_rf = {}\n",
    "breast_cancer_results_rf['accuracy'] = accuracy_score(y_test_breast_cancer, y_pred_rf_breast)\n",
    "breast_cancer_results_rf['f1'] = f1_score(y_test_breast_cancer, y_pred_rf_breast)\n",
    "breast_cancer_results_rf['recall'] = recall_score(y_test_breast_cancer, y_pred_rf_breast)\n",
    "breast_cancer_results_rf['precision'] = precision_score(y_test_breast_cancer, y_pred_rf_breast)\n",
    "breast_cancer_results_rf[\"time\"] = total_time\n",
    "breast_cancer_results_rf[\"best_params\"] = f\"n = {best_params['n_estimators']}, m = {best_params['max_features']}, s = {best_params['max_samples']}\"\n",
    "breast_cancer_results_rf[\"confusion_matrix\"] = confusion_matrix(y_test_breast_cancer, y_pred_rf_breast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.9635036496350365,\n",
       " 'f1': 0.9494949494949494,\n",
       " 'recall': 0.9791666666666666,\n",
       " 'precision': 0.9215686274509803,\n",
       " 'time': 686.0711133480072,\n",
       " 'best_params': 'n = 100, m = 0.2, s = 0.1',\n",
       " 'confusion_matrix': array([[85,  4],\n",
       "        [ 1, 47]], dtype=int64)}"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "breast_cancer_results_rf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Para el conjunto de datos de arroz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_distributions = {\n",
    "    'n_estimators': [10, 50, 100, 200],\n",
    "    'max_features': ['sqrt', 'log2', None] + list(np.arange(0.1, 1.1, 0.1)),\n",
    "    'max_samples': [0.1, 0.5, 0.6, 0.7, 0.8, 0.9, None]  # O un rango de valores que consideres adecuados\n",
    "}\n",
    "\n",
    "random_search = RandomizedSearchCV(RandomForestClassifierOptimized(), param_distributions, n_iter=100, cv=5, random_state=42)\n",
    "\n",
    "# Medición del tiempo de \"preparación\" y ajuste de parámetros\n",
    "start_time = time.time()\n",
    "random_search.fit(X_train_rice, y_train_rice)\n",
    "end_time = time.time()\n",
    "\n",
    "# Tiempo total utilizado en el proceso\n",
    "total_time = end_time - start_time\n",
    "\n",
    "# Resultados de RandomizedSearchCV\n",
    "best_params = random_search.best_params_\n",
    "best_score = random_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener el mejor clasificador\n",
    "best_clf_rf_rice = random_search.best_estimator_\n",
    "\n",
    "# Entrenar el mejor clasificador\n",
    "best_clf_rf_rice.fit(X_train_rice, y_train_rice)\n",
    "\n",
    "# Predecir las etiquetas de clase para los datos de prueba\n",
    "y_pred_rf_rice = best_clf_rf_rice.predict(X_test_rice)\n",
    "\n",
    "rice_results_rf = {}\n",
    "rice_results_rf['accuracy'] = accuracy_score(y_test_rice, y_pred_rf_rice)\n",
    "rice_results_rf['f1'] = f1_score(y_test_rice, y_pred_rf_rice)\n",
    "rice_results_rf['recall'] = recall_score(y_test_rice, y_pred_rf_rice)\n",
    "rice_results_rf['precision'] = precision_score(y_test_rice, y_pred_rf_rice)\n",
    "rice_results_rf[\"time\"] = total_time\n",
    "rice_results_rf[\"best_params\"] = f\"n = {best_params['n_estimators']}, m = {best_params['max_features']}, s = {best_params['max_samples']}\"\n",
    "rice_results_rf[\"confusion_matrix\"] = confusion_matrix(y_test_rice, y_pred_rf_rice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.9146981627296588,\n",
       " 'f1': 0.9267192784667418,\n",
       " 'recall': 0.9426605504587156,\n",
       " 'precision': 0.9113082039911308,\n",
       " 'time': 686.0711133480072,\n",
       " 'best_params': 'n = 100, m = 0.2, s = 0.1',\n",
       " 'confusion_matrix': array([[286,  40],\n",
       "        [ 25, 411]], dtype=int64)}"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rice_results_rf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Para el dataset de frijoles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definición de los parámetros a probar\n",
    "param_distributions = {\n",
    "    'n_estimators': [10, 50, 100],\n",
    "    'max_features': ['sqrt', 'log2'] + list(np.arange(0.1, 1.1, 0.1)),\n",
    "    'max_samples': [0.1, 0.5, 0.8, 0.9, None]  # O un rango de valores que consideres adecuados\n",
    "}\n",
    "\n",
    "random_search = RandomizedSearchCV(RandomForestClassifierOptimized(), param_distributions, n_iter=100, cv=5, random_state=42)\n",
    "\n",
    "# Medición del tiempo de \"preparación\" y ajuste de parámetros\n",
    "start_time = time.time()\n",
    "random_search.fit(X_train_dry_bean, y_train_dry_bean)\n",
    "end_time = time.time()\n",
    "\n",
    "# Tiempo total utilizado en el proceso\n",
    "total_time = end_time - start_time\n",
    "\n",
    "# Resultados de RandomizedSearchCV\n",
    "best_params = random_search.best_params_\n",
    "best_score = random_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener el mejor clasificador\n",
    "best_clf_rf_dry_bean = random_search.best_estimator_\n",
    "\n",
    "# Entrenar el mejor clasificador\n",
    "best_clf_rf_dry_bean.fit(X_train_dry_bean, y_train_dry_bean)\n",
    "\n",
    "# Predecir las etiquetas de clase para los datos de prueba\n",
    "y_pred_rf_dry_bean = best_clf_rf_dry_bean.predict(X_test_dry_bean)\n",
    "\n",
    "dry_bean_results_rf = classification_report(y_test_dry_bean, y_pred_rf_dry_bean, output_dict=True)\n",
    "dry_bean_results_rf['accuracy'] = accuracy_score(y_test_dry_bean, y_pred_rf_dry_bean)\n",
    "dry_bean_results_rf[\"time\"] = total_time\n",
    "dry_bean_results_rf[\"best_params\"] = f\"n = {best_params['n_estimators']}, m = {best_params['max_features']}, s = {best_params['max_samples']}\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('dry_bean_results_rf.txt', 'w') as file:\n",
    "    file.write(str(dry_bean_results_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN\n",
    "Para el conjunto de datos de cáncer de mama de Wisconsin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNNClassifier()\n",
    "\n",
    "# Definir un diccionario con los rangos de parámetros a probar\n",
    "param_grid = {\n",
    "    'n_neighbors': [5, 7, 8, 9, 10, 15],\n",
    "}\n",
    "\n",
    "# Inicializar GridSearchCV con validación cruzada de 5 particiones (20% de los datos para prueba)\n",
    "grid_search = GridSearchCV(knn, param_grid, cv=5, scoring='f1')\n",
    "\n",
    "# Medición del tiempo de \"preparación\" y ajuste de parámetros\n",
    "start_time = time.time()\n",
    "grid_search.fit(X_train_breast_cancer, y_train_breast_cancer)\n",
    "end_time = time.time()\n",
    "\n",
    "# Tiempo total utilizado en el proceso\n",
    "total_time = end_time - start_time\n",
    "\n",
    "# Resultados de GridSearchCV\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores parámetros (Breast Cancer - KNN): {'n_neighbors': 7}\n",
      "Mejor puntuación F1 (Breast Cancer - KNN): 0.9629882720113342\n",
      "Tiempo total de preparación y ajuste de parámetros (Breast Cancer - KNN): 11.682685852050781\n"
     ]
    }
   ],
   "source": [
    "print(\"Mejores parámetros (Breast Cancer - KNN):\", best_params)\n",
    "print(\"Mejor puntuación F1 (Breast Cancer - KNN):\", best_score)\n",
    "print(\"Tiempo total de preparación y ajuste de parámetros (Breast Cancer - KNN):\", total_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener el mejor clasificador\n",
    "best_clf_knn_breast = grid_search.best_estimator_\n",
    "\n",
    "# Entrenar el mejor clasificador\n",
    "best_clf_knn_breast.fit(X_train_breast_cancer, y_train_breast_cancer)\n",
    "\n",
    "# Predecir las etiquetas de clase para los datos de prueba\n",
    "y_pred_knn_breast = best_clf_knn_breast.predict(X_test_breast_cancer)\n",
    "\n",
    "breast_cancer_results_knn = {}\n",
    "breast_cancer_results_knn['accuracy'] = accuracy_score(y_test_breast_cancer, y_pred_knn_breast)\n",
    "breast_cancer_results_knn['f1'] = f1_score(y_test_breast_cancer, y_pred_knn_breast)\n",
    "breast_cancer_results_knn['recall'] = recall_score(y_test_breast_cancer, y_pred_knn_breast)\n",
    "breast_cancer_results_knn['precision'] = precision_score(y_test_breast_cancer, y_pred_knn_breast)\n",
    "breast_cancer_results_knn[\"time\"] = total_time\n",
    "breast_cancer_results_knn[\"best_params\"] = f\"k = {best_params['n_neighbors']}\"\n",
    "breast_cancer_results_knn[\"confusion_matrix\"] = confusion_matrix(y_test_breast_cancer, y_pred_knn_breast)\n",
    "\n",
    "with open('breast_cancer_results_knn.txt', 'w') as file:\n",
    "    file.write(str(breast_cancer_results_knn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Para el conjunto de datos de arroz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'n_neighbors': [5, 7, 8, 9, 10, 15],\n",
    "}\n",
    "\n",
    "# Inicializar GridSearchCV con validación cruzada de 5 particiones (20% de los datos para prueba)\n",
    "grid_search = GridSearchCV(knn, param_grid, cv=5, scoring='f1')\n",
    "\n",
    "# Medición del tiempo de \"preparación\" y ajuste de parámetros\n",
    "start_time = time.time()\n",
    "grid_search.fit(X_train_rice, y_train_rice)\n",
    "end_time = time.time()\n",
    "\n",
    "# Tiempo total utilizado en el proceso\n",
    "total_time = end_time - start_time\n",
    "\n",
    "# Resultados de GridSearchCV\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores parámetros (Rice - KNN): {'n_neighbors': 7}\n",
      "Mejor puntuación F1 (Rice - KNN): 0.9386749054019443\n",
      "Tiempo total de preparación y ajuste de parámetros (Rice - KNN): 401.91310596466064\n"
     ]
    }
   ],
   "source": [
    "print(\"Mejores parámetros (Rice - KNN):\", best_params)\n",
    "print(\"Mejor puntuación F1 (Rice - KNN):\", best_score)\n",
    "print(\"Tiempo total de preparación y ajuste de parámetros (Rice - KNN):\", total_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener el mejor clasificador\n",
    "best_clf_knn_rice = grid_search.best_estimator_\n",
    "\n",
    "# Entrenar el mejor clasificador\n",
    "best_clf_knn_rice.fit(X_train_rice, y_train_rice)\n",
    "\n",
    "# Predecir las etiquetas de clase para los datos de prueba\n",
    "y_pred_knn_rice = best_clf_knn_rice.predict(X_test_rice)\n",
    "\n",
    "rice_results_knn = {}\n",
    "rice_results_knn['accuracy'] = accuracy_score(y_test_rice, y_pred_knn_rice)\n",
    "rice_results_knn['f1'] = f1_score(y_test_rice, y_pred_knn_rice)\n",
    "rice_results_knn['recall'] = recall_score(y_test_rice, y_pred_knn_rice)\n",
    "rice_results_knn['precision'] = precision_score(y_test_rice, y_pred_knn_rice)\n",
    "rice_results_knn[\"time\"] = total_time\n",
    "rice_results_knn[\"best_params\"] = f\"k = {best_params['n_neighbors']}\"\n",
    "rice_results_knn[\"confusion_matrix\"] = confusion_matrix(y_test_rice, y_pred_knn_rice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('rice_results_knn.txt', 'w') as file:\n",
    "    file.write(str(rice_results_knn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Para el dataset de frijoles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'n_neighbors': [8, 9, 10, 15],\n",
    "}\n",
    "\n",
    "# Inicializar GridSearchCV con validación cruzada de 5 particiones (20% de los datos para prueba)\n",
    "grid_search = GridSearchCV(knn, param_grid, cv=5, scoring='f1_macro')\n",
    "\n",
    "# Medición del tiempo de \"preparación\" y ajuste de parámetros\n",
    "start_time = time.time()\n",
    "grid_search.fit(X_train_dry_bean, y_train_dry_bean)\n",
    "end_time = time.time()\n",
    "\n",
    "# Tiempo total utilizado en el proceso\n",
    "total_time = end_time - start_time\n",
    "\n",
    "# Resultados de GridSearchCV\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores parámetros (Beans - KNN): {'n_neighbors': 8}\n",
      "Mejor puntuación F1 (Beans - KNN): 0.70793128611238\n",
      "Tiempo total de preparación y ajuste de parámetros (Beans - KNN): 3096.580188035965\n"
     ]
    }
   ],
   "source": [
    "print(\"Mejores parámetros (Beans - KNN):\", best_params)\n",
    "print(\"Mejor puntuación F1 (Beans - KNN):\", best_score)\n",
    "print(\"Tiempo total de preparación y ajuste de parámetros (Beans - KNN):\", total_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Obtener el mejor clasificador\n",
    "best_clf_knn_dry_bean = grid_search.best_estimator_\n",
    "\n",
    "# Entrenar el mejor clasificador\n",
    "best_clf_knn_dry_bean.fit(X_train_dry_bean, y_train_dry_bean)\n",
    "\n",
    "# Predecir las etiquetas de clase para los datos de prueba\n",
    "y_pred_knn_dry_bean = best_clf_knn_dry_bean.predict(X_test_dry_bean)\n",
    "\n",
    "# Resultados de clasificación\n",
    "dry_bean_results_knn = classification_report(y_test_dry_bean, y_pred_knn_dry_bean, output_dict=True)\n",
    "dry_bean_results_knn['accuracy'] = accuracy_score(y_test_dry_bean, y_pred_knn_dry_bean)\n",
    "dry_bean_results_knn[\"time\"] = total_time\n",
    "dry_bean_results_knn[\"best_params\"] = f\"k = {best_params['n_neighbors']}\"\n",
    "dry_bean_results_knn[\"confusion_matrix\"] = confusion_matrix(y_test_dry_bean, y_pred_knn_dry_bean)\n",
    "\n",
    "with open('dry_bean_results_knn.txt', 'w') as file:\n",
    "    file.write(str(dry_bean_results_knn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save all results\n",
    "\n",
    "with open('breast_cancer_results_kde.txt', 'w') as file:\n",
    "    file.write(str(breast_cancer_results_kde))\n",
    "\n",
    "with open('rice_results_kde.txt', 'w') as file:\n",
    "    file.write(str(rice_results_kde))\n",
    "\n",
    "with open('dry_bean_results_kde.txt', 'w') as file:\n",
    "    file.write(str(dry_bean_results_kde))\n",
    "\n",
    "with open('breast_cancer_results_cart.txt', 'w') as file:\n",
    "    file.write(str(breast_cancer_results_cart))\n",
    "\n",
    "with open('rice_results_cart.txt', 'w') as file:\n",
    "    file.write(str(rice_results_cart))\n",
    "\n",
    "with open('dry_bean_results_cart.txt', 'w') as file:\n",
    "    file.write(str(dry_bean_results_cart))\n",
    "\n",
    "with open('breast_cancer_results_rf.txt', 'w') as file:\n",
    "    file.write(str(breast_cancer_results_rf))\n",
    "\n",
    "with open('rice_results_rf.txt', 'w') as file:\n",
    "    file.write(str(rice_results_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'C': [0.1, 1, 10, 50, 60, 70, 80, 90, 100],\n",
    "    'gamma': [0.1, 0.01, 0.001, 0.0001, 0.005, 'scale'],\n",
    "    'kernel': ['rbf', 'linear']\n",
    "}\n",
    "\n",
    "# Crear una instancia de GridSearchCV con la clase SVMOptimizer y el espacio de búsqueda\n",
    "grid_search = GridSearchCV(SVMOptimizer(), param_grid, cv=5)\n",
    "\n",
    "# Medición del tiempo de \"preparación\" y ajuste de parámetros\n",
    "start_time = time.time()\n",
    "grid_search.fit(X_train_breast_cancer, y_train_breast_cancer)\n",
    "end_time = time.time()\n",
    "\n",
    "# Tiempo total utilizado en el proceso\n",
    "total_time = end_time - start_time\n",
    "\n",
    "# Resultados de GridSearchCV\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores parámetros (Breast Cancer - SVM): {'C': 69, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "Mejor puntuación F1 (Breast Cancer - SVM): 0.9725437864887407\n",
      "Tiempo total de preparación y ajuste de parámetros (Breast Cancer - SVM): 12.407183647155762\n"
     ]
    }
   ],
   "source": [
    "print(\"Mejores parámetros (Breast Cancer - SVM):\", best_params)\n",
    "print(\"Mejor puntuación F1 (Breast Cancer - SVM):\", best_score)\n",
    "print(\"Tiempo total de preparación y ajuste de parámetros (Breast Cancer - SVM):\", total_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener el mejor clasificador\n",
    "best_clf_svm_breast = grid_search.best_estimator_\n",
    "\n",
    "# Predecir las etiquetas de clase para los datos de prueba\n",
    "y_pred_svm_breast = best_clf_svm_breast.predict(X_test_breast_cancer)\n",
    "\n",
    "breast_cancer_results_svm = {}\n",
    "breast_cancer_results_svm['accuracy'] = accuracy_score(y_test_breast_cancer, y_pred_svm_breast)\n",
    "breast_cancer_results_svm['f1'] = f1_score(y_test_breast_cancer, y_pred_svm_breast)\n",
    "breast_cancer_results_svm['recall'] = recall_score(y_test_breast_cancer, y_pred_svm_breast)\n",
    "breast_cancer_results_svm['precision'] = precision_score(y_test_breast_cancer, y_pred_svm_breast)\n",
    "breast_cancer_results_svm[\"time\"] = total_time\n",
    "breast_cancer_results_svm[\"best_params\"] = f\"C = {best_params['C']}, gamma = {best_params['gamma']}, kernel = {best_params['kernel']}\"\n",
    "breast_cancer_results_svm[\"confusion_matrix\"] = confusion_matrix(y_test_breast_cancer, y_pred_svm_breast)\n",
    "\n",
    "with open('breast_cancer_results_svm.txt', 'w') as file:\n",
    "    file.write(str(breast_cancer_results_svm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Para el conjunto de datos de arroz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'C': [0.1, 1, 5, 6, 6.5, 7, 8, 9, 10, 20],\n",
    "    'gamma': [1, 0.5, 0.1, 0.01, 'scale'],\n",
    "    'kernel': ['rbf']\n",
    "}\n",
    "\n",
    "# Crear una instancia de GridSearchCV con la clase SVMOptimizer y el espacio de búsqueda\n",
    "grid_search = GridSearchCV(SVMOptimizer(), param_grid, cv=5)\n",
    "\n",
    "# Medición del tiempo de \"preparación\" y ajuste de parámetros\n",
    "start_time = time.time()\n",
    "grid_search.fit(X_train_rice, y_train_rice)\n",
    "end_time = time.time()\n",
    "\n",
    "# Tiempo total utilizado en el proceso\n",
    "total_time = end_time - start_time\n",
    "\n",
    "# Resultados de GridSearchCV\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "# Obtener el mejor clasificador\n",
    "best_clf_svm_rice = grid_search.best_estimator_\n",
    "\n",
    "best_score = grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores parámetros (Rice - SVM): {'C': 6, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "Mejor puntuación F1 (Rice - SVM): 0.9725437864887407\n",
      "Tiempo total de preparación y ajuste de parámetros (Rice - SVM): 28.33565664291382\n"
     ]
    }
   ],
   "source": [
    "print(\"Mejores parámetros (Rice - SVM):\", best_params)\n",
    "print(\"Mejor puntuación F1 (Rice - SVM):\", best_score)\n",
    "print(\"Tiempo total de preparación y ajuste de parámetros (Rice - SVM):\", total_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predecir las etiquetas de clase para los datos de prueba\n",
    "y_pred_svm_rice = best_clf_svm_rice.predict(X_test_rice)\n",
    "\n",
    "rice_results_svm = {}\n",
    "rice_results_svm['accuracy'] = accuracy_score(y_test_rice, y_pred_svm_rice)\n",
    "rice_results_svm['f1'] = f1_score(y_test_rice, y_pred_svm_rice)\n",
    "rice_results_svm['recall'] = recall_score(y_test_rice, y_pred_svm_rice)\n",
    "rice_results_svm['precision'] = precision_score(y_test_rice, y_pred_svm_rice)\n",
    "rice_results_svm[\"time\"] = total_time\n",
    "rice_results_svm[\"best_params\"] = f\"C = {best_params['C']}, gamma = {best_params['gamma']}, kernel = {best_params['kernel']}\"\n",
    "rice_results_svm[\"confusion_matrix\"] = confusion_matrix(y_test_rice, y_pred_svm_rice)\n",
    "\n",
    "with open('rice_results_svm.txt', 'w') as file:\n",
    "    file.write(str(rice_results_svm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Para el dataset de frijoles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'C': [0.01, 0.1, 1],\n",
    "    'kernel': ['linear']\n",
    "}\n",
    "\n",
    "# Crear una instancia de GridSearchCV con la clase SVMOptimizer y el espacio de búsqueda\n",
    "grid_search = GridSearchCV(SVMOptimizer(), param_grid, cv=5, n_jobs=-1, verbose=2)\n",
    "\n",
    "# Medición del tiempo de \"preparación\" y ajuste de parámetros\n",
    "start_time = time.time()\n",
    "grid_search.fit(X_train_dry_bean, y_train_dry_bean)\n",
    "end_time = time.time()\n",
    "\n",
    "# Tiempo total utilizado en el proceso\n",
    "total_time = end_time - start_time\n",
    "\n",
    "# Resultados de GridSearchCV\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "# Obtener el mejor clasificador\n",
    "best_clf_svm_dry_bean = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores parámetros (Beans - SVM): {'C': 1, 'kernel': 'linear'}\n",
      "Mejor puntuación F1 (Beans - SVM): 0.9149529284577517\n",
      "Tiempo total de preparación y ajuste de parámetros (Beans - SVM): 661.5432448387146\n"
     ]
    }
   ],
   "source": [
    "print(\"Mejores parámetros (Beans - SVM):\", best_params)\n",
    "print(\"Mejor puntuación F1 (Beans - SVM):\", best_score)\n",
    "print(\"Tiempo total de preparación y ajuste de parámetros (Beans - SVM):\", total_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener el mejor clasificador\n",
    "best_clf_rf_breast = random_search.best_estimator_\n",
    "\n",
    "# Predecir las etiquetas de clase para los datos de prueba\n",
    "y_pred_svm_rice = \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
